{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Modeling\n",
    "\n",
    "---\n",
    "\n",
    "In this phase, I will perform the following tasks:\n",
    "\n",
    "1. Compare Models\n",
    "2. Train Model\n",
    "3. Evalueate Model\n",
    "4. Conclusion\n",
    "5. Refrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**\n",
    "\n",
    "Lead the necessary libraries and output data file from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:08:20.125466Z",
     "start_time": "2025-03-09T16:08:19.980487Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import json\n",
    "import warnings\n",
    "\n",
    "from prophet import Prophet\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "avocados_df = pd.read_csv(\"../data/processed/avocado_processed.csv\")\n",
    "avocados_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Compare Models\n",
    "\n",
    "---\n",
    "\n",
    "In this section, I will have to compare the performance of different models and choose the best one. I will be using models with multi feature support (multivaried). Furthermore, since I want to predict the price of avocados fir the entire next month at once, I will be using multi-step forecasting. As this dataset is a time series data, I will compare the following models:\n",
    "\n",
    "- ARIMA (AutoRegressive Integrated Moving Average), SARIMA (Seasonal ARIMA) and SARIMAX (multivaried Seasonal ARIMA)\n",
    "- XGBoost (Extreme Gradient Boosting)\n",
    "- Prophet (Facebook's Time Series Forecasting Library)\n",
    "\n",
    "**ARIMA, SARIMA and SARIMAX**\n",
    "\n",
    "These methods are all used for understanding and predicting future values of a timeseries dataset [1]. They have been widely used as powerful tools to predict future values based on historical data, however, they require a very good understanding of the data and can be sensitive how it's hyperparameters have been tuned [2]. Since SARIMA is a statistical model, the data should be stationary. SARIMAX is the multivaried version of SARIAM (univaried), accepting multiple exogenous features. \n",
    "\n",
    "**XGBoost**\n",
    "\n",
    "XGBoost is an open-source library that provides efficient gradiant boosting implementation (trend-based forcasting). However, it mainly specializes in working with tree ensembles and is not specifically designed for time series data [3]. Furthermore, XGBoost has proved to be highly effective in modeling financial data, while methods like SARIMA exels at sales forcasting [4]. As a result, I will not use this model in my comparison.\n",
    "\n",
    "**Prophet**\n",
    "\n",
    "Prophet is a forecasting tool developed by Facebook. It is designed for analyzing time series that display patterns on different time scales such as yearly, weekly and daily. It also has advanced features for handling missing data, holidays, and other special events [5]. This model is the latest tool that has shown an improved performance in terms of accuracy of prediction [6]. Although it might provide a good performance with minimum tuning and understanding of the data, it can be prone to poor failure in some domains [2]. Eventhough this dataset does not contain any missing values so that I can leverage its ability to handle missing values, I will use this model to see if it can outperform the other models. This model does not need the inpit data to be stationary as it handles trends and seasonality it self. Prophet also supports multiple features and is also considered a suitable candidate.\n",
    "\n",
    "> Note: As the seasonal decomopsition in the 'Data Understaning' section suggested, the data seems to be seasonal (SARIMA and Prophet are more suitable) rather than trending (ARIMA and XGBoost). Along with the facts mentioned above, I will only compare SARIMA and Prophet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train Model\n",
    "\n",
    "---\n",
    "\n",
    "In this section, I will first train a SARIMA model and then a Prophet model, and then compare them together to select the best performing one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SARIMAX_DF = avocados_df.copy()\n",
    "SARIMAX_DF[\"date\"] = pd.to_datetime(avocados_df[\"date\"])\n",
    "\n",
    "target = \"average_price\"\n",
    "features = [\"total_volume\", \"4046\", \"4225\", \"4770\", \"type_conventional\", \"type_organic\"]\n",
    "\n",
    "sarimax_config = {\n",
    "    'target': target,\n",
    "    'features': features,\n",
    "    'train_test_split': 0.7,\n",
    "    'order': (1, 1, 1),\n",
    "    'seasonal_order': (1, 1, 1, 12)\n",
    "}\n",
    "\n",
    "train_size = int(len(SARIMAX_DF) * sarimax_config['train_test_split'])\n",
    "train, test = SARIMAX_DF[:train_size], SARIMAX_DF[train_size:]\n",
    "\n",
    "sarimax_model = SARIMAX(\n",
    "    train[sarimax_config['target']], \n",
    "    exog=train[sarimax_config['features']],\n",
    "    order=sarimax_config['order'], \n",
    "    seasonal_order=sarimax_config['seasonal_order'],\n",
    ")\n",
    "sarimax_results = sarimax_model.fit()\n",
    "\n",
    "sarimax_forecast = sarimax_results.get_forecast(steps=len(test), exog=test[sarimax_config['features']])\n",
    "sarimax_pred = sarimax_forecast.predicted_mean\n",
    "\n",
    "sarimax_mse = mean_squared_error(test[sarimax_config['target']], sarimax_pred)\n",
    "sarimax_rmse = np.sqrt(sarimax_mse)\n",
    "sarimax_mae = mean_absolute_error(test[sarimax_config['target']], sarimax_pred)\n",
    "sarimax_r2 = r2_score(test[sarimax_config['target']], sarimax_pred)\n",
    "\n",
    "print(\"SARIMAX Model Performance Metrics:\")\n",
    "print(f\"Mean Squared Error (MSE): {sarimax_mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {sarimax_rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {sarimax_mae:.4f}\")\n",
    "print(f\"R-squared Score (R2): {sarimax_r2:.4f}\")\n",
    "print(f\"Model Accuracy: {(1 - sarimax_mae) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results of SARIMAX trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(SARIMAX_DF.index, SARIMAX_DF[sarimax_config['target']], label=\"Actual Prices\", color='blue', linestyle='dashed')\n",
    "plt.plot(test.index, sarimax_pred, label=\"SARIMAX Predicted Prices\", color='red')\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average Price\")\n",
    "plt.title(\"Avocado Price Forecast using SARIMAX (Multiple Features)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"average_price\"\n",
    "features = [\"total_volume\", \"4046\", \"4225\", \"4770\", \"type_conventional\", \"type_organic\"]\n",
    "\n",
    "prophet_config = {\n",
    "    'target': target,\n",
    "    'features': features,\n",
    "    'train_test_split': 0.8,\n",
    "    'model_params': {\n",
    "        'seasonality_mode': \"multiplicative\",\n",
    "        'changepoint_prior_scale': 0.1,\n",
    "        'weekly_seasonality': False,\n",
    "        'yearly_seasonality': False,\n",
    "        'daily_seasonality': False,\n",
    "        'monthly_seasonality': {'name': 'monthly', 'period': 1, 'fourier_order': 5}\n",
    "    }\n",
    "}\n",
    "\n",
    "PROPHET_DF = avocados_df.reset_index()[[\"date\", prophet_config['target']] + prophet_config['features']].rename(\n",
    "    columns={\"date\": \"ds\", prophet_config['target']: \"y\"}\n",
    ")\n",
    "PROPHET_DF[\"ds\"] = pd.to_datetime(PROPHET_DF[\"ds\"])\n",
    "PROPHET_DF = PROPHET_DF.dropna()\n",
    "\n",
    "train_size = int(len(PROPHET_DF) * prophet_config['train_test_split'])\n",
    "train = PROPHET_DF[:train_size].copy()\n",
    "test = PROPHET_DF[train_size:].copy()\n",
    "\n",
    "prophet_model = Prophet(\n",
    "    seasonality_mode=prophet_config['model_params']['seasonality_mode'],\n",
    "    changepoint_prior_scale=prophet_config['model_params']['changepoint_prior_scale'],\n",
    "    weekly_seasonality=prophet_config['model_params']['weekly_seasonality'],\n",
    "    yearly_seasonality=prophet_config['model_params']['yearly_seasonality'],\n",
    "    daily_seasonality=prophet_config['model_params']['daily_seasonality']\n",
    ")\n",
    "\n",
    "prophet_model.add_seasonality(**prophet_config['model_params']['monthly_seasonality'])\n",
    "\n",
    "for feature in prophet_config['features']:\n",
    "    prophet_model.add_regressor(feature)\n",
    "\n",
    "prophet_model.fit(train)\n",
    "\n",
    "future_dates = test[[\"ds\"] + prophet_config['features']].copy()\n",
    "\n",
    "prophet_forecast = prophet_model.predict(future_dates)\n",
    "\n",
    "test = test.set_index(\"ds\")\n",
    "prophet_pred = prophet_forecast.set_index(\"ds\")[\"yhat\"].reindex(test.index)\n",
    "\n",
    "prophet_mse = mean_squared_error(test[\"y\"], prophet_pred)\n",
    "prophet_rmse = np.sqrt(prophet_mse)\n",
    "prophet_mae = mean_absolute_error(test[\"y\"], prophet_pred)\n",
    "prophet_r2 = r2_score(test[\"y\"], prophet_pred)\n",
    "\n",
    "print(\"\\nOptimized Prophet Model Performance Metrics (Quarterly Seasonality):\")\n",
    "print(f\"Mean Squared Error (MSE): {prophet_mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {prophet_rmse:.4f}\")\n",
    "print(f\"Mean Absolute Error (MAE): {prophet_mae:.4f}\")\n",
    "print(f\"R-squared Score (R2): {prophet_r2:.4f}\")\n",
    "print(f\"Model Accuracy: {(1 - prophet_mae) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the results of Prophet trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(PROPHET_DF[\"ds\"], PROPHET_DF[\"y\"], label=\"Actual Prices\", color='blue', linestyle='dashed')\n",
    "plt.plot(test.index, prophet_pred, label=\"Prophet Predicted Prices\", color='green')\n",
    "\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Average Price\")\n",
    "plt.title(\"Avocado Price Forecast using Prophet (Multiple Features)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some iterations, I realized that the Prophet model benefits from more training data. Hence, I changed the `train_test_split` from 0.7 to 0.8 (even though the data mining success criteria limits the size of the training set to 0.7).\n",
    "\n",
    "By changing the `changepoint_prior_scale` from 0.05 to higher and lower values, the performance of the model did not show any improvement. Hence, I left it as 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: It seems that the SARIMAX model is complaining about the data being non-stationary, even though I have already performed the stationarity test and the data is stationary. My data prepration step might have introduced this to the data. However, due to the time constraint, I will not be able to fix this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Evalueate Models\n",
    "\n",
    "---\n",
    "\n",
    "For evaluating the accuracy of each model, I have used the following metrics:\n",
    "\n",
    "- Mean Absolute Error (MAE) [Measures average of absolute errors.] [lower is better]\n",
    "- Mean Squared Error (MSE) [Measures the average of squared errors.] [lower is better]\n",
    "- R-squared (R²) [Measures the proportion of variance explained by model.] [higher is better]\n",
    "- Mean Absolute Percentage Error (MAPE) [Measures error as a percentage of actual values.] [lower is better]\n",
    "\n",
    "Each of these metrics is a measure of the difference between the predicted and actual values. Using multiple metrics helps with a more comprehensive evaluation of the model's performance. As shown below, the SARIMAX model has shown far better accuracy than the Prophet model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = {\n",
    "    'Prophet': {\n",
    "        'MAE (lower is better)': prophet_mae,\n",
    "        'MSE (lower is better)': prophet_mse,\n",
    "        'R² (higher is better)': prophet_r2,\n",
    "        'RMSE (lower is better)': prophet_rmse\n",
    "    },\n",
    "    'SARIMAX': {\n",
    "        'MAE (lower is better)': sarimax_mae,\n",
    "        'MSE (lower is better)': sarimax_mse,\n",
    "        'R² (higher is better)': sarimax_r2,\n",
    "        'RMSE (lower is better)': sarimax_rmse\n",
    "    }\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Model Performance Comparison', fontsize=16, y=1.02)\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "colors = ['#2ecc71', '#3498db']\n",
    "\n",
    "for idx, metric in enumerate(['MAE (lower is better)', 'MSE (lower is better)', 'R² (higher is better)', 'RMSE (lower is better)']):\n",
    "    metric_values = [metrics[metric] for metrics in model_metrics.values()]\n",
    "    \n",
    "    bars = axes[idx].bar(model_metrics.keys(), metric_values, color=colors)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        axes[idx].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                      f'{height:.4f}',\n",
    "                      ha='center', va='bottom')\n",
    "    \n",
    "    axes[idx].set_title(f'{metric}')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    axes[idx].set_ylabel('Score')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is evident that the SARIMAX model has shown far better accuracy than the Prophet model, even though SARIMAX is complaining about the data being non-stationary. This could be due to the small training set size, or misconfiguration of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Model**\n",
    "\n",
    "Save the models and their configurations for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:08:20.319586Z",
     "start_time": "2025-03-09T16:08:20.315693Z"
    }
   },
   "outputs": [],
   "source": [
    "joblib.dump(prophet_model, \"../models/prophet/prophet_avocado_model.pkl\")\n",
    "with open(\"../models/prophet/prophet_config.json\", \"w\") as f:\n",
    "    json.dump(prophet_config, f, indent=4)\n",
    "\n",
    "joblib.dump(sarimax_model, \"../models/sarimax/sarimax_avocado_model.pkl\") \n",
    "with open(\"../models/sarimax/sarimax_config.json\", \"w\") as f:\n",
    "    json.dump(sarimax_config, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Conclusion\n",
    "\n",
    "---\n",
    "\n",
    "So far, I have trained a SARIMAX model and a Prophet model using multiple features on the same dataset, and evaluated their accuracy. The SARIMAX model has shown far better accuracy than the Prophet model. This could be due to many reasons, such as the small training set size, or misconfiguration of the model. As a result, I will use the SARIMAX model for the final prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Refrences\n",
    "\n",
    "----\n",
    "\n",
    "[1] “Autoregressive integrated moving average,” Wikipedia, https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average (accessed Mar. 9, 2025).\n",
    "\n",
    "[2] K. Kutzkov, “ARIMA vs Prophet vs LSTM for Time Series Prediction,” Neptune.ai, Jan. 24, 2025. [Online]. Available: https://neptune.ai/blog/arima-vs-prophet-vs-lstm. [Accessed: Mar. 9, 2025].\n",
    "\n",
    "[3] “XGBoost,” Wikipedia, https://en.wikipedia.org/wiki/XGBoost (accessed Mar. 9, 2025).\n",
    "\n",
    "[4] D. S. Chandel, R. Singh, B. Tiwari, A. Arora, and U. Mhatre, “A Journey into the Future: An Applied Exploration of Time Series Forecasting,” Databricks Community Technical Blog, Jan. 9, 2024. [Online]. Available: https://community.databricks.com/t5/technical-blog/a-journey-into-the-future-an-applied-exploration-of-time-series/ba-p/55494. [Accessed: Mar. 9, 2025].\n",
    "\n",
    "[5] https://facebook.github.io/prophet/\n",
    "\n",
    "[6] B. K. Jha and S. Pande, “Time Series Forecasting Model for Supermarket Sales using FB Prophet,” 2021 5th International Conference on Computing Methodologies and Communication (ICCMC), Erode, India, 2021, pp. 547-552."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
