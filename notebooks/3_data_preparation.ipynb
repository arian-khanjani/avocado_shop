{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Data Preparation\n",
    "\n",
    "---\n",
    "\n",
    "In this phase, I will perform the following tasks:\n",
    "\n",
    "1. Handling outliers\n",
    "2. Scale numerical features\n",
    "3. Enumeration of categorical variables (using <em>one hot encoding</em>)\n",
    "4. Feature analysis\n",
    "5. Data Resampling\n",
    "6. Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**\n",
    "\n",
    "Lead the necessary libraries and output data file from the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:04:52.491619Z",
     "start_time": "2025-03-09T16:04:52.463628Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "avocados_df = pd.read_csv(\"../data/interim/avocado_cleaned.csv\")\n",
    "avocados_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Handling Outliers\n",
    "\n",
    "---\n",
    "\n",
    "#### Average Price\n",
    "\n",
    "There are two commonly used methods to identify outliers: **Z-score** and **IQR**. Median and IQR measures the central tendency and spread, respectively, but are robust against outliers and non-normal data [2]. As the dataset is small and there have been so many potential outliers highlighted in the box-plots in the previous steps, the **Z-score** might flag too many points as outliers. Therefore, I will use the **IQR** method to identify outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:04:52.579943Z",
     "start_time": "2025-03-09T16:04:52.517098Z"
    }
   },
   "outputs": [],
   "source": [
    "average_price_Q1 = avocados_df['average_price'].quantile(0.25)\n",
    "average_price_Q3 = avocados_df['average_price'].quantile(0.75)\n",
    "average_price_IQR = average_price_Q3 - average_price_Q1\n",
    "\n",
    "average_price_lower_bound = average_price_Q1 - 1.5 * average_price_IQR\n",
    "average_price_upper_bound = average_price_Q3 + 1.5 * average_price_IQR\n",
    "\n",
    "average_price_outliers_mask = (avocados_df['average_price'] < average_price_lower_bound) | (avocados_df['average_price'] > average_price_upper_bound)\n",
    "average_price_outliers = avocados_df[average_price_outliers_mask]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(avocados_df['average_price'])\n",
    "plt.title('Boxplot of Average Price')\n",
    "plt.ylabel('Average Price')\n",
    "plt.show()\n",
    "\n",
    "print(\"Q0.25:\", average_price_Q1)\n",
    "print(\"Q0.75:\", average_price_Q3)\n",
    "print('IQR:', average_price_IQR)\n",
    "print(\"Lower bound:\", average_price_lower_bound)\n",
    "print(\"Upper bound:\", average_price_upper_bound)\n",
    "print(\"Number of average_price:\", avocados_df['average_price'].shape[0])\n",
    "print(\"Number of outliers:\", average_price_outliers.shape[0])\n",
    "avocados_df[['average_price']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the `average_price` and `total_volume` are the target variables, and the number of outliers is not significant, I will not remove any outliers from these columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLU 4046\n",
    "\n",
    "As demonstrated in the previous sections by the boxplots, the PLU code columns contain many outliers that need to be investigated and addressed. I will use the **IQR** method to identify the outliers. These outliers are likely to be the result of the ambigious regions and the aggregation of those regions.\n",
    "\n",
    "First, I will calculate the IQR for the PLU 4046 column, describe the outliers and plot the boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:04:52.641065Z",
     "start_time": "2025-03-09T16:04:52.597744Z"
    }
   },
   "outputs": [],
   "source": [
    "plu_4046_Q1 = avocados_df['4046'].quantile(0.25)\n",
    "plu_4046_Q3 = avocados_df['4046'].quantile(0.75)\n",
    "plu_4046_IQR = plu_4046_Q3 - plu_4046_Q1\n",
    "\n",
    "old_plu_4046_lower_bound = plu_4046_Q1 - 1.5 * plu_4046_IQR # the result of this calculation is negative, as price cannot be negative, we will use 0 as the lower bound\n",
    "plu_4046_lower_bound = 0\n",
    "plu_4046_upper_bound = plu_4046_Q3 + 1.5 * plu_4046_IQR\n",
    "\n",
    "plu_4046_outliers_mask = (avocados_df['4046'] < plu_4046_lower_bound) | (avocados_df['4046'] > plu_4046_upper_bound)\n",
    "plu_4046_outliers = avocados_df[plu_4046_outliers_mask]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(avocados_df['4046'])\n",
    "plt.title('Boxplot of PLU 4046 Volume Sale')\n",
    "plt.ylabel('PLU 4046 Volume Sale')\n",
    "plt.show()\n",
    "\n",
    "print(\"Q0.25:\", plu_4046_Q1)\n",
    "print(\"Q0.75:\", plu_4046_Q3)\n",
    "print('IQR:', plu_4046_IQR)\n",
    "print(\"Lower bound (Actual):\", old_plu_4046_lower_bound)\n",
    "print(\"Lower bound (Manual):\", plu_4046_lower_bound)\n",
    "print(\"Upper bound:\", plu_4046_upper_bound)\n",
    "print(\"Number of PLU 4046:\", avocados_df['4046'].shape[0])\n",
    "print(\"Number of outliers for PLU 4046:\", plu_4046_outliers.shape[0])\n",
    "\n",
    "avocados_df['4046'].describe().apply(lambda x: f'{x:,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The identified outliers in the PLU 4046 are numerous; hence, I need to investigate whether they are the result of an error or if they are valid data points.\n",
    "\n",
    "> **Note**: The lower bound being negative could either due to negative values or skewed distribution of extreme outliers, affecting the IQR calculation. Inorder to avoid removing any valid data points, I will use 0 as the lower bound when ever it is calculated to be negative.\n",
    "\n",
    "> **Note**: Since the regions of the dataset were scrambled, these outliers might simply be the result of aggregation of different regions of different sizes. Hence the data is better to be normalized by using the mode of <em>each month</em> instead of the whole data or each year, in order not to lose the monthly seasonality of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I will plot the volume sale of PLU 4046 for each month, with and without the outliers and also with the outliers replaced by the mode of each month using boxplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:04:53.171887Z",
     "start_time": "2025-03-09T16:04:52.798365Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 10))\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(x='month_name', y='4046', data=avocados_df)\n",
    "plt.title('PLU 4046 Volume Sale Boxplot for Each Month')\n",
    "plt.ylabel('PLU 4046 Volume Sale')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Month')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "zonder_outliers = avocados_df.drop(plu_4046_outliers.index)\n",
    "sns.boxplot(x='month_name', y='4046', data=zonder_outliers)\n",
    "plt.title('PLU 4046 Volume Sale Boxplot (Without Outliers) for Each Month')\n",
    "plt.ylabel('PLU 4046 Volume Sale')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Month')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "mode_season_4046 = avocados_df.copy()\n",
    "mode_season_4046['4046_replaced_outliers'] = mode_season_4046['4046']\n",
    "for month in mode_season_4046['month_name'].unique():\n",
    "    mask = (mode_season_4046['month_name'] == month) & plu_4046_outliers_mask\n",
    "    mode = mode_season_4046[mask]['4046'].mode()\n",
    "    mode_season_4046.loc[mask, '4046_replaced_outliers'] = mode[0]\n",
    "\n",
    "sns.boxplot(x='month_name', y='4046_replaced_outliers', data=mode_season_4046)\n",
    "plt.title('PLU 4046 Volume Sale Boxplot (Outliers Replaced by Mode) for Each Month')\n",
    "plt.ylabel('PLU 4046 Volume Sale')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the analysis above shows the importance of not removing the outliers but to normalize the data by using the mode of each month and make sure the seasonality of the data is kept intact. As the extreme outliers (big regions) are most likely an aggregation of smaller regions. I tried to replace the outliers of each month with the mode value of it. The result seems to be more balanced and the seasonality is preserved, although shifted as evident that for example 'September's maximum value was higher than 'Augusts' maximum value, but after replacing the outliers with the mode value, it is the other way around. However, it could possibly be because of the regions aggregations.\n",
    "\n",
    "I will apply the changes to the main dataframe instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:04:53.195273Z",
     "start_time": "2025-03-09T16:04:53.189084Z"
    }
   },
   "outputs": [],
   "source": [
    "avocados_df['4046'] = mode_season_4046['4046_replaced_outliers']\n",
    "avocados_df['4046'].describe().apply(lambda x: f'{x:,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLU 4225\n",
    "\n",
    "Now I will do the same to the other PLU codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:04:53.258875Z",
     "start_time": "2025-03-09T16:04:53.251780Z"
    }
   },
   "outputs": [],
   "source": [
    "plu_4225_Q1 = avocados_df['4225'].quantile(0.25)\n",
    "plu_4225_Q3 = avocados_df['4225'].quantile(0.75)\n",
    "plu_4225_IQR = plu_4225_Q3 - plu_4225_Q1\n",
    "\n",
    "old_plu_4225_lower_bound = plu_4225_Q1 - 1.5 * plu_4225_IQR # the result of this calculation is negative, as price cannot be negative, we will use 0 as the lower bound\n",
    "plu_4225_lower_bound = 0\n",
    "plu_4225_upper_bound = plu_4225_Q3 + 1.5 * plu_4225_IQR\n",
    "\n",
    "plu_4225_outliers_mask = (avocados_df['4225'] < plu_4225_lower_bound) | (avocados_df['4225'] > plu_4225_upper_bound)\n",
    "plu_4225_outliers = avocados_df[plu_4225_outliers_mask]\n",
    "\n",
    "print(\"Q0.25:\", plu_4225_Q1)\n",
    "print(\"Q0.75:\", plu_4225_Q3)\n",
    "print('IQR:', plu_4225_IQR)\n",
    "print(\"Lower bound (Actual):\", old_plu_4225_lower_bound)\n",
    "print(\"Lower bound (Manual):\", plu_4225_lower_bound)\n",
    "print(\"Upper bound:\", plu_4225_upper_bound)\n",
    "print(\"Number of PLU 4225:\", avocados_df['4225'].shape[0])\n",
    "print(\"Number of outliers for PLU 4225:\", plu_4225_outliers.shape[0])\n",
    "\n",
    "avocados_df['4225'].describe().apply(lambda x: f'{x:,.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:04:53.336660Z",
     "start_time": "2025-03-09T16:04:53.318554Z"
    }
   },
   "outputs": [],
   "source": [
    "mode_season_4225 = avocados_df.copy()\n",
    "mode_season_4225['4225_replaced_outliers'] = mode_season_4225['4225']\n",
    "for month in mode_season_4225['month_name'].unique():\n",
    "    mask = (mode_season_4225['month_name'] == month) & plu_4225_outliers_mask\n",
    "    mode = mode_season_4225[mask]['4225'].mode()\n",
    "    mode_season_4225.loc[mask, '4225_replaced_outliers'] = mode[0]\n",
    "\n",
    "avocados_df['4225'] = mode_season_4225['4225_replaced_outliers']\n",
    "avocados_df['4225'].describe().apply(lambda x: f'{x:,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLU 4770"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:04:53.417243Z",
     "start_time": "2025-03-09T16:04:53.410424Z"
    }
   },
   "outputs": [],
   "source": [
    "plu_4770_Q1 = avocados_df['4770'].quantile(0.25)\n",
    "plu_4770_Q3 = avocados_df['4770'].quantile(0.75)\n",
    "plu_4770_IQR = plu_4770_Q3 - plu_4770_Q1\n",
    "\n",
    "old_plu_4770_lower_bound = plu_4770_Q1 - 1.5 * plu_4770_IQR  # the result of this calculation is negative, as price cannot be negative, we will use 0 as the lower bound\n",
    "plu_4770_lower_bound = 0\n",
    "plu_4770_upper_bound = plu_4770_Q3 + 1.5 * plu_4770_IQR\n",
    "\n",
    "plu_4770_outliers_mask = (avocados_df['4770'] < plu_4770_lower_bound) | (avocados_df['4770'] > plu_4770_upper_bound)\n",
    "plu_4770_outliers = avocados_df[plu_4770_outliers_mask]\n",
    "\n",
    "print(\"Q0.25:\", plu_4770_Q1)\n",
    "print(\"Q0.75:\", plu_4770_Q3)\n",
    "print('IQR:', plu_4770_IQR)\n",
    "print(\"Lower bound (Actual):\", old_plu_4770_lower_bound)\n",
    "print(\"Lower bound (Manual):\", plu_4770_lower_bound)\n",
    "print(\"Upper bound:\", plu_4770_upper_bound)\n",
    "print(\"Number of PLU 4770:\", avocados_df['4770'].shape[0])\n",
    "print(\"Number of outliers for PLU 4770:\", plu_4770_outliers.shape[0])\n",
    "\n",
    "avocados_df['4770'].describe().apply(lambda x: f'{x:,.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \n",
    "Convert Categorical values to numerical values for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:04:53.486449Z",
     "start_time": "2025-03-09T16:04:53.470905Z"
    }
   },
   "outputs": [],
   "source": [
    "mode_season_4770 = avocados_df.copy()\n",
    "mode_season_4770['4770_replaced_outliers'] = mode_season_4770['4770']\n",
    "for month in mode_season_4770['month_name'].unique():\n",
    "    mask = (mode_season_4770['month_name'] == month) & plu_4770_outliers_mask\n",
    "    mode = mode_season_4770[mask]['4770'].mode()\n",
    "    mode_season_4770.loc[mask, '4770_replaced_outliers'] = mode[0]\n",
    "\n",
    "avocados_df['4770'] = mode_season_4770['4770_replaced_outliers']\n",
    "avocados_df['4770'].describe().apply(lambda x: f'{x:,.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will plot each PLU code again using boxplots to see the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:04:53.683623Z",
     "start_time": "2025-03-09T16:04:53.552035Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('4225')\n",
    "plt.boxplot(avocados_df['4225'])\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('4046')\n",
    "plt.boxplot(avocados_df['4046'])\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.boxplot(avocados_df['4770'])\n",
    "plt.title('4770')\n",
    "plt.ylabel('PLU 4225 Volume Sale')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afte the imputation of outliers by the mode of each month, the boxplots show that all the 3 PLU codes are now more balanced and normalized, containing minimum outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Scale Numerical Features\n",
    "\n",
    "---\n",
    "\n",
    "In order to make it easier to work with data (as this dataset has many large scale features) and also to improve the performance of the model, I will scale the numerical features in this step. This can be achieved using techniques such as Min-Max and Max-Abs Scaling or Standardization. These methods are generally sensitive to outliers, however, Z-Score Standardization is said to be robust against outliers [3]. Even though I have handled the outliers as much as I could, I still do not trust the data, so I will use the Z-Score Standardization method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:04:53.794919Z",
     "start_time": "2025-03-09T16:04:53.717824Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "numerical_columns = ['average_price', 'total_volume', '4046', '4225', '4770', 'total_bags']\n",
    "avocados_df[numerical_columns] = scaler.fit_transform(avocados_df[numerical_columns])\n",
    "avocados_df[numerical_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Enumeration of Categorical Variables (One Hot Encoding)\n",
    "\n",
    "---\n",
    "\n",
    "In order to use the categorical variables in the model, I will convert them to numerical values using the **One Hot Encoding** method. This method has been adopted for its simplicity and effectiveness. The following columns will be converted:\n",
    "\n",
    "- `type`\n",
    "- `area`\n",
    "- `season`\n",
    "\n",
    "In <em>One Hot Encoding</em>, each category is represented as a binary vector. The vector is all zero (or false) values except for the index of the category, which is marked with a 1 (or true)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:04:53.871076Z",
     "start_time": "2025-03-09T16:04:53.857398Z"
    }
   },
   "outputs": [],
   "source": [
    "avocados_df_copy = avocados_df.copy()\n",
    "\n",
    "avocados_df = pd.get_dummies(avocados_df, columns=['area', 'type', 'month_name'], drop_first=False, dtype=int)\n",
    "\n",
    "print(avocados_df.shape)\n",
    "\n",
    "avocados_df.columns = avocados_df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "avocados_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the enumeration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:04:53.909992Z",
     "start_time": "2025-03-09T16:04:53.899221Z"
    }
   },
   "outputs": [],
   "source": [
    "area_cols = [col for col in avocados_df.columns if col.startswith('area_')]\n",
    "type_cols = [col for col in avocados_df.columns if col.startswith('type_')]\n",
    "month_name_cols = [col for col in avocados_df.columns if col.startswith('month_name_')]\n",
    "\n",
    "print(\"Validating one-hot encoding:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "area_sums = avocados_df[area_cols].sum(axis=1)\n",
    "print(\"\\nArea encoding validation:\")\n",
    "print(f\"Number of unique areas per row: {area_sums.unique()}\")\n",
    "print(f\"All rows have exactly one area: {(area_sums == 1).all()}\")\n",
    "print(f\"Areas encoded: {', '.join(col.replace('area_','') for col in area_cols)}\")\n",
    "\n",
    "type_sums = avocados_df[type_cols].sum(axis=1)\n",
    "print(\"\\nType encoding validation:\")\n",
    "print(f\"Number of unique types per row: {type_sums.unique()}\")\n",
    "print(f\"All rows have exactly one type: {(type_sums == 1).all()}\")\n",
    "print(f\"Types encoded: {', '.join(col.replace('type_','') for col in type_cols)}\")\n",
    "\n",
    "month_sums = avocados_df[month_name_cols].sum(axis=1)\n",
    "print(\"\\nMonth encoding validation:\")\n",
    "print(f\"Number of unique months per row: {month_sums.unique()}\")\n",
    "print(f\"All rows have exactly one month: {(month_sums == 1).all()}\")\n",
    "print(f\"Months encoded: {', '.join(col.replace('month_name_','') for col in month_name_cols)}\")\n",
    "\n",
    "print(\"\\nChecking for null values after encoding:\")\n",
    "null_counts = avocados_df[area_cols + type_cols + month_name_cols].isnull().sum()\n",
    "print(f\"Total null values: {null_counts.sum()}\")\n",
    "if null_counts.sum() > 0:\n",
    "    print(\"Columns with null values:\")\n",
    "    print(null_counts[null_counts > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Feature Analysis\n",
    "\n",
    "---\n",
    "\n",
    "#### Heatmap\n",
    "\n",
    "I will try to identify the correlation between the features again after the recent changes to see if my modifications have had any effect. This way I can better select my target features for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entire Dataset Correlation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:04:55.254348Z",
     "start_time": "2025-03-09T16:04:54.685051Z"
    }
   },
   "outputs": [],
   "source": [
    "avocados_df['date'] = pd.to_datetime(avocados_df['date'])\n",
    "\n",
    "corr_matrix = avocados_df.corr()\n",
    "\n",
    "plt.figure(figsize=(20, 14))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix of Avocado Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, I do not see much difference in the heatmap. The correlation between the features and the target variables is still very low. The only new observation is that the `type_organic` column has a positive correlation with the target variable `average_price`!\n",
    "\n",
    "Based on the heatmap, I can deduct the following key points:\n",
    "\n",
    "- The `conventional` avocado type has a strong <em>positive</em> correlation with the PLU codes.\n",
    "- The `conventional` avocado type has a <em>positive</em> correlation with the `total_bags` and `total_volume`.\n",
    "- The `conventional` avocado type has a <em>negative</em> correlation with the `average_price`.\n",
    "- The `conventional` avocado type has a strong <em>negative</em> correlation with the PLU codes.\n",
    "- The `conventional` avocado type has a <em>negative</em> correlation with the `total_bags` and `total_volume`.\n",
    "- The `conventional` avocado type has a <em>positive</em> correlation with the `average_price`.\n",
    "- The new Area columns are slightly effective on the `average_price` and PLU codes, but the effect is not very strong. Hence, I will remove them.\n",
    "- The new Months columns are not very effective on the target, either my data preparation has not been done correctly or the data is not suitable for this kind of analysis. As they do not have much effect, I will remove them.\n",
    "- The `total_bags` and `total_volume` are highly correlated with each other, which is expected as they are both measures of the same thing (this could suggest that one of them is redundant, so I will remove `total_bags`).\n",
    "- The `year` column also does not seem to have any effect on any other feature. I will remove this column too.\n",
    "- The `total_bags` and `total_volume` are negatively correlated with the `average_price`.\n",
    "\n",
    "In general, I believe that the modifications I have made have made the data more balanced and the correlation between the features and the target variables is now more visible. Hence, I will proceed with the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the features do not have any string or meaningful correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [col for col in avocados_df.columns if col.startswith(('area_', 'month_name_'))]\n",
    "avocados_df = avocados_df.drop(columns=columns_to_drop)\n",
    "\n",
    "avocados_df = avocados_df.drop(columns=['total_bags', 'year'])\n",
    "avocados_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Data Resampling\n",
    "\n",
    "---\n",
    "\n",
    "Resampling the data to match the aimed prediction frequency (monthly) can help the forecasting model capture important monthly trends and simplify the modeling process [1]. In order to do so, I will resample the data to monthly frequency and plot the `Average Price` and `Total Volume` trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avocados_df[\"date\"] = pd.to_datetime(avocados_df[\"date\"])\n",
    "\n",
    "avocados_df = avocados_df.groupby(avocados_df[\"date\"].dt.to_period(\"M\")).mean(numeric_only=True)\n",
    "avocados_df = avocados_df.reset_index()\n",
    "avocados_df[\"date\"] = avocados_df[\"date\"].dt.to_timestamp()\n",
    "monthly_df = avocados_df.set_index(\"date\")\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.plot(avocados_df.index, avocados_df[\"average_price\"], label=\"Average Price\")\n",
    "plt.plot(avocados_df.index, avocados_df[\"total_volume\"], label=\"Total Volume\")\n",
    "plt.title(\"Monthly Avocado Trends\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is resampled to monthly frequency and seems to be ready for the next step (Modeling). Even though the data has majorly lost its granularity, resampling is an important process to help the forecasting model capture the monthly trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save Output**\n",
    "\n",
    "Save the output to a new CSV file for the next step (3 Modeling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-09T16:04:55.489860Z",
     "start_time": "2025-03-09T16:04:55.297600Z"
    }
   },
   "outputs": [],
   "source": [
    "avocados_df = avocados_df.sort_index(axis=1)\n",
    "avocados_df.to_csv(\"../data/processed/avocado_processed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Conclusion\n",
    "\n",
    "---\n",
    "\n",
    "So far I have prepared the data as much as I could and have made the following changes:\n",
    "\n",
    "- Identified the `average_price` outliers using the **IQR** method but did not delete them.\n",
    "- Handled the `PLU 4046`, `PLU 4225`, and `PLU 4770` outliers using the **IQR** method by replacing them with the mode of each month.\n",
    "- Enumerated the categorical variables using the **One Hot Encoding** method.\n",
    "- Analyzed the correlation between the features and the target variables after the recent changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 References\n",
    "\n",
    "[1] N. Kourentzes, F. Petropoulos, and J. R. Trapero, “Improving forecasting by estimating time series structural components across multiple frequencies,” International Journal of Forecasting, vol. 30, no. 2, pp. 291–302, Apr. 2014. doi: 10.1016/j.ijforecast.2013.09.006.\n",
    "\n",
    "[2] A. K. Mishra, “Outlier Detection in Time-Series Receive Signal Strength Observation Using Z-Score Method with Sn Scale Estimator for Indoor Localization,” IEEE Sensors Journal, vol. 19, no. 13, pp. 5148–5155, July 2019. doi: 10.1109/JSEN.2019.2909738.\n",
    "\n",
    "[3] A. Yıldız, M. E. Er, A. Bursalı, T. Çolakoğlu, and E. C. Erkuş, “The Effects of Data Standardization and Normalization Techniques in Click Through Rate Prediction,” in Proceedings of the 11th International Conference on Advanced Technologies (ICAT’23), 2023, pp. 200–203. doi: 10.58190/icat.2023.48."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######\n",
    "The density of your data should be the same as how much you want to predict. If you want to predict the next 5 mins, your data density must be 5 mins.\n",
    "\n",
    "First, define prediction rate (how long)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
